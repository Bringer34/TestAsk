Обе задачи решались посредствам ВПН. 
С помощью бесплатных прокси не удавалось подключиться к сайтам, а платные отсутствуют. 

1) Задача № 1 выполнена, результат предоставлен. 
Наведение на ховер, парсинг данных, вывод информации в csv файл с сортировкой по алфавиту.
Далее имтация работы пользователя.

2) Задача № 2 не выполнена. Понял, что для парсинга страницы надо прогрузить javascript код. Если сделать обычный запрос через requests по ссылке страницы Илона Маска (https://x.com/elonmusk), то в теле можно найти ссылку https://twitter.com/x/migrate?tok=7b2265223a222f656c6f6e6d75736b222c2274223a313732353838343535357d306b4883603d2cb43199aebb0b9b1ae8.
Далее я пробовал ее рендерить с помощью requests_html и HTMLSession. Получал код, ссылки.
Пробовал ходить по ним, рендерить, искал информацию. По итогу найти информацию о твиттах не получилось.
Также пробовал анализировать get запросы, которые передавались на сайте при попытке вручную открыть страницу. Пробовал их воспроизводить в программе, тоже не особо давало результат. 

Наиболее результативная попытка получилась при помощи библиотеки pyppeteer. С помощью нее была запущена страница и выполнен парс статей, однако непонятно будет ли данный метод корректен для текущей задачи.  К тому же здесь нужна доработка, поскольку есть ряд нюансов (код предоставил, хоть и выводит информацию о статьях, но выводит не 10 штук и явно нужны доработки).

По итогу попробовал разные методы, поиск информации и т.п., но с задачей № 2 не справился. К сожалению не могу много времени тратить на поиск информации по данной задаче, поскольку на работе сейчас этап завершение проекта low code разработки. Поэтому предоставляю все что есть.
